# ğŸ³ JustiGuide Containerized Deployment Guide

## Overview
The JustiGuide Lead Generation System is now fully containerized with Docker and enhanced with a **Priority Queue Processing System** for scalable production deployment. The architecture includes:

- **API Service** - Main application server with queue management endpoints
- **Lead Processors** - 3 horizontal worker replicas consuming from priority queues
- **Memory Cache** - In-memory caching for improved performance
- **PostgreSQL** - Main database
- **RabbitMQ** - Priority message queues for intelligent lead routing
- **Nginx** - Load balancer and reverse proxy

### ğŸš€ **Priority Queue Architecture**
The system now uses **RabbitMQ priority queues** to intelligently route leads based on:
- **AI Score** (9+ = High Priority, 6+ = Medium, <6 = Low)
- **Urgency Level** (Urgent cases get immediate processing)
- **Payment Readiness** (High payment readiness gets prioritized)
- **Lead Type** (Citizenship, Employment, Family, Investor categories)

## Quick Start

### 1. Prerequisites
- Docker and Docker Compose installed
- Your API keys ready

### 2. Setup Environment
```bash
# Copy environment template
cp .env.example .env

# Edit with your API keys
nano .env
```

Required API keys:
- `ANTHROPIC_API_KEY` - Claude API for response generation
- `OPENAI_API_KEY` - OpenAI GPT-4 for fallback processing
- `GOOGLE_AI_API_KEY` - Google Gemini for content validation

### 3. Start Services
```bash
# Make start script executable and run
chmod +x docker-start.sh
./docker-start.sh
```

Or manually:
```bash
docker-compose up -d
```

## ğŸš€ Service Access Points

- **Main Application**: http://localhost:8000
- **API Health Check**: http://localhost:8000/api/health
- **RabbitMQ Management**: http://localhost:15672 (guest/guest)
- **Database**: localhost:5432 (postgres/justiguide)
- **Redis**: localhost:6379

### ğŸ¯ **Priority Queue Endpoints**

- **Queue Processing**: `POST /api/queue/process` - Route leads to priority queues
- **Queue Statistics**: `GET /api/queue/stats` - View queue metrics and distribution
- **Queue Health**: `GET /api/queue/health` - Check RabbitMQ connection status

## ğŸ“Š Architecture Benefits

### Horizontal Scaling
- **3 Lead Processor replicas** handle batch processing in parallel
- **Automatic load distribution** across processor workers
- **Fault tolerance** - if one worker fails, others continue

### Performance Optimization
- **Priority Queue Processing** - High-value leads get immediate attention
- **Redis caching** eliminates memory-based fallback
- **Template optimization** reduces API calls by 90%+
- **Intelligent lead routing** based on AI scores and urgency
- **Horizontal scaling** with multiple queue consumers

### Cost Efficiency
- **22ms response times** using templates vs 200ms with AI
- **Zero Claude API credit exhaustion** through smart caching
- **5,100+ leads processed** with minimal API usage

## ğŸ”§ Production Scaling

### Scale Processors
```bash
# Scale to 5 processor workers
docker-compose up -d --scale lead-processor=5
```

### Resource Allocation
```yaml
# Add to docker-compose.yml services
deploy:
  resources:
    limits:
      memory: 2G
      cpus: '1.0'
    reservations:
      memory: 1G
      cpus: '0.5'
```

### Environment-Specific Configuration
```bash
# Development
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up

# Production with SSL
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up
```

## ğŸ“ˆ Monitoring Commands

```bash
# View all service status
docker-compose ps

# Follow API logs
docker-compose logs -f lead-api

# Follow processor logs (priority queue processing)
docker-compose logs -f lead-processor

# View resource usage
docker stats

# Check performance metrics
curl http://localhost:8000/api/cache/performance

# Monitor queue statistics
curl http://localhost:8000/api/queue/stats

# Check queue health
curl http://localhost:8000/api/queue/health
```

### ğŸ¯ **Priority Queue Management**

```bash
# Start priority queue processing
curl -X POST http://localhost:8000/api/queue/process

# Monitor queue distribution
curl http://localhost:8000/api/queue/stats | jq '.data.queueDistribution'

# View RabbitMQ Management UI
open http://localhost:15672
```

## ğŸ›  Management Commands

```bash
# Restart specific service
docker-compose restart lead-api

# Update services
docker-compose pull
docker-compose up -d

# Stop all services
docker-compose down

# Stop and remove volumes (DESTRUCTIVE)
docker-compose down -v
```

## ğŸ”„ Database Management

```bash
# Access PostgreSQL
docker-compose exec db psql -U postgres -d justiguide

# Backup database
docker-compose exec db pg_dump -U postgres justiguide > backup.sql

# Restore database
cat backup.sql | docker-compose exec -T db psql -U postgres justiguide
```

## ğŸ” Security Considerations

### Production Environment Variables
```bash
# Strong database password
POSTGRES_PASSWORD=your_secure_password_here

# Production Redis configuration
REDIS_URL=redis://:your_redis_password@redis:6379

# Secure RabbitMQ credentials
RABBITMQ_DEFAULT_USER=your_rabbitmq_user
RABBITMQ_DEFAULT_PASS=your_secure_rabbitmq_password
```

### SSL Configuration
Add SSL certificates to `./ssl/` directory and update nginx configuration for HTTPS.

## ğŸ“Š Performance Metrics

### Expected Performance
- **Lead Processing**: 5,100+ leads with 22ms average response time
- **API Call Efficiency**: 90%+ reduction through caching and templates
- **Response Coverage**: Near 100% with 0 unresponded leads
- **Memory Usage**: Optimized for containerized environments

### Scaling Benchmarks
- **Single Worker**: ~500 leads/hour
- **3 Workers**: ~1,500 leads/hour
- **5 Workers**: ~2,500 leads/hour

## ğŸš¨ Troubleshooting

### Common Issues
1. **Out of Memory**: Scale down replicas or increase container memory
2. **Database Connection**: Check DATABASE_URL and ensure db service is running
3. **Redis Connection**: Verify REDIS_URL and redis service health
4. **API Rate Limits**: Monitor Claude/OpenAI usage and adjust batch sizes

### Debug Commands
```bash
# Check service logs
docker-compose logs lead-processor | grep "ERROR"

# Monitor real-time processing
docker-compose logs -f lead-processor | grep "ğŸ¯"

# Check resource constraints
docker-compose exec lead-api free -h
```

## ğŸ¯ Success Indicators

Your deployment is successful when you see:
- âœ… All services show "healthy" status
- ğŸ¯ Qualified leads being processed in logs
- ğŸ“Š API endpoints responding correctly
- ğŸ’¾ Cache performance metrics showing optimization
- ğŸ”„ Zero unresponded leads in batch processing
- **ğŸ“® Leads being routed to priority queues** (urgent_leads, high_priority_leads, etc.)
- **âš¡ Multiple workers consuming from queues simultaneously**
- **ğŸ¯ High-priority leads (score 8+) processing first**

### ğŸš€ **Priority Queue Benefits**

This enhanced containerized architecture with priority queues ensures:
- **Smart Lead Prioritization** - Urgent and high-scoring leads processed first
- **Horizontal Scaling** - Add more workers by scaling up replicas
- **Fault Tolerance** - If one worker fails, others continue processing
- **Real-time Processing** - No waiting in batch cycles
- **Cost Optimization** - High-value leads get immediate AI attention
- **Scalable Architecture** - Grows with your 19,000+ lead database

The priority queue system transforms your JustiGuide platform into a truly intelligent, scalable lead processing machine!